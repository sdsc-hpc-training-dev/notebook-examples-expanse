{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Install: sentence-transformers\n",
    "# Module Needed: request, json, pprint, bs4(Beautiful Soap), time,SentenceTransformer, Scipy.spatial, numpy, datetime, matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Prerequisites\n",
    "\n",
    "Make sure that you have the following python packages installed:\n",
    "* ``` conda install requests ```\n",
    "\n",
    "* ``` conda install json ```\n",
    "\n",
    "* ``` conda install pprint ```\n",
    "\n",
    "* ``` conda install bs4 ```\n",
    "\n",
    "* ``` pip install lxml ```\n",
    "\n",
    "* ``` conda install pytorch torchvision cudatoolkit=10.0 -c pytorch ```\n",
    "\n",
    "* ``` pip install -U sentence-transformers ```\n",
    "\n",
    "* ``` conda install scipy ```\n",
    "\n",
    "* ``` conda install datetime ```\n",
    "\n",
    "* ``` conda install matplotlib ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REHS 2020 \n",
    "#Created by Dhruv Kumar\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/gseo/.local/lib/python3.8/site-packages (2.5.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 656 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from sentence-transformers) (8.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/gseo/.local/lib/python3.8/site-packages (from sentence-transformers) (4.39.0)\n",
      "Requirement already satisfied: tqdm in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from sentence-transformers) (4.59.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/gseo/.local/lib/python3.8/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/gseo/.local/lib/python3.8/site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: scikit-learn in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: numpy in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from sentence-transformers) (1.20.1)\n",
      "Requirement already satisfied: scipy in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from sentence-transformers) (1.6.2)\n",
      "Requirement already satisfied: filelock in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gseo/.local/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: requests in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gseo/.local/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gseo/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: jinja2 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: sympy in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.8)\n",
      "Requirement already satisfied: networkx in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/gseo/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.99)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/gseo/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/gseo/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2021.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from networkx->torch>=1.11.0->sentence-transformers) (5.0.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /cm/shared/apps/spack/0.17.3/cpu/b/opt/spack/linux-rocky8-zen/gcc-8.5.0/anaconda3-2021.05-q4munrgvh7qp4o7r3nzcdkbuph4z7375/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.5.1\n",
      "    Uninstalling sentence-transformers-2.5.1:\n",
      "      Successfully uninstalled sentence-transformers-2.5.1\n",
      "Successfully installed sentence-transformers-2.6.0\n"
     ]
    }
   ],
   "source": [
    "# New Package Install \n",
    "!pip install -U sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "The forum that we will be scraping is a discourse forum called The Bank of New Zealand. It discusses topics related to people's banking issues as well as any problems people encounter while using the Bank of New Zealand mobile app. The forum is moderately active and has a large number of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather metadata about the posts\n",
    "i = 0\n",
    "all_submissions = []\n",
    "crawler_condition = True\n",
    "while crawler_condition == True:\n",
    "    print(i)\n",
    "    url = \"https://community.bnz.co.nz/latest.json?no_definitions=true&page=\"+str(i)\n",
    "    r = (requests.get(url)).text\n",
    "    raw_dictionary = json.loads(r)\n",
    "\n",
    "    #contains info of 30 submissions bc there are 30 submissions on a page\n",
    "    submissions_on_page = raw_dictionary['topic_list']['topics']\n",
    "    if len(submissions_on_page) <= 0:\n",
    "        crawler_condition = False\n",
    "        break\n",
    "    else:\n",
    "        for submission in submissions_on_page:\n",
    "            dic = {}\n",
    "            dic[\"id\"] = submission[\"id\"]\n",
    "            dic[\"title\"] = submission[\"title\"]\n",
    "            dic[\"slug\"] = submission[\"slug\"]\n",
    "            dic[\"replies\"] = submission[\"reply_count\"]\n",
    "            dic[\"created_at\"] = submission[\"created_at\"][0:7]#we only want the year and month\n",
    "            dic[\"views\"] = submission[\"views\"]\n",
    "            dic[\"likes\"] = submission[\"like_count\"]\n",
    "            dic[\"category_id\"] = submission[\"category_id\"]\n",
    "            dic[\"question\"] = \" \"  #empty placeholder for now\n",
    "            all_submissions.append(dic)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given post url (specified by a slug and id) it will return the question of the post\n",
    "def get_forum_message(message):\n",
    "    soup = BeautifulSoup(message,\"lxml\")   \n",
    "    div = soup.find(\"div\", {\"itemprop\": \"articleBody\"})\n",
    "    submission_text = ''\n",
    "    ht = div.findAll('p') \n",
    "    for i in ht:\n",
    "        submission_text += i.get_text()  \n",
    "    return submission_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the slugs and ids from all_submissions to create urls. We use the urls to get the message(question) of the post. Note that there is a time.sleep function because if we try fetching too quickly from the website, it will not let us, and return a None type. Thus, the below code might take 5-10 minutes. If you get an error that states that there is a None type, try changing the input for ``` time.sleep() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(all_submissions)):\n",
    "    submission = all_submissions[i]\n",
    "    topic_url = (\"https://community.bnz.co.nz/t/\" + submission[\"slug\"] + '/' + str(submission[\"id\"]))\n",
    "    print(str(i) + \" \"+ topic_url)\n",
    "    response = requests.get(topic_url)\n",
    "    message = response.text\n",
    "    question = get_forum_message(message)\n",
    "    submission[\"question\"] = question\n",
    "    if i % 10 == 0:\n",
    "        time.sleep(5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a dictionary called all_submissions which is an array of dictionaries. To clarify further, each element in all_submissions is a dictionary. Each disctionary represents all the data about one post. For example, the first element in all_submissions is a dictionary with the information about the first post. The dictionary contains data such as the number of views, likes, the slug, the id number, title, and question of the post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Model\n",
    "\n",
    "Now that we have the question and title of the post (as well as other metadata), we can build a recommendation model. This model will return the top 5 posts that are most similar to the current post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [x[\"title\"] for x in all_submissions]\n",
    "questions = [x[\"question\"] for x in all_submissions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make the recommendation system based on either the title of the post (topic_names) or the question (questions).\n",
    "Note that creating the embeddings using the question will take much longer (approx 1 hour) compared to using the titles.\n",
    "The below example uses the titles of the posts. To use the question themselves, change ```topic_names[i]``` to ```questions[i]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings = []\n",
    "for i in range(len(questions)):\n",
    "    embedings.append(embedder.encode(topic_names[i]))\n",
    "    print(str(i/len(questions)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the cosine similarity between two vectors. Since we are using cosine similarity, a distance of 0 between the vectors means that they are the same. A distance of 1.0 means that they are orthogonal (very different). Note that we have used 1.0-dist as the metric. Thus 1.0 means the same and 0 means very different.\n",
    "\n",
    "Distances is a 2D matrix with each vector compared to all other vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for vector1 in embedings:\n",
    "    temp = []\n",
    "    for vector2 in embedings:\n",
    "        dist = scipy.spatial.distance.cdist(vector1, vector2, \"cosine\")\n",
    "        temp.append(1.0 - dist)\n",
    "    distances.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the top N-1 elements in list1 (it finds the top N elements, but removes the first one because the first\n",
    "#element is the same post (itself))\n",
    "\n",
    "def Nmaxelements(list1, N): \n",
    "    final_list = [] \n",
    "    list1_copy = list1.copy() \n",
    "\n",
    "    for i in range(0, N):  \n",
    "        max1 = 0\n",
    "        for j in range(len(list1_copy)):      \n",
    "            if list1_copy[j] > max1: \n",
    "                max1 = list1_copy[j]; \n",
    "\n",
    "        list1_copy.remove(max1); \n",
    "        final_list.append([i,max1,topic_names[i]]) \n",
    "\n",
    "    return(final_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = []\n",
    "for i in range(len(questions)):\n",
    "    recommendations.append(Nmaxelements(distances[i],6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recommendations is a 2D array. Each element in recommendations is an array that contains the top 6 (top 5, because it removes itself,which is most similar to itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulazing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the number of posts created during each month on this forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we convert the all_submissions dictionary into a 2D array called temp_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submissions = [] #2D array with information similar to that in all_submissions \n",
    "for i in all_submissions:\n",
    "    submission = []\n",
    "    submission.append(i[\"replies\"])\n",
    "    submission.append(i[\"views\"])\n",
    "    submission.append(i[\"likes\"])\n",
    "    submission.append(i[\"category_id\"])\n",
    "    submission.append(i[\"created_at\"])\n",
    "    temp_submissions.append(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we find the unique number of dates and sort them (earliest --> present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(set([x[4] for x in temp_submissions])) #unique dates\n",
    "dates = np.array(dates)\n",
    "dates = np.sort(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make a list postsADay, which countains the number of posts created on a specific month/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsADay = [0] * len(dates)\n",
    "for i in temp_submissions:\n",
    "    for j in range(len(dates)):\n",
    "        if i[4] == dates[j]:\n",
    "            postsADay[j] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathplotlib needs a different format for the dates. Thus, we convert the dates in the array dates to matplotlib dates and append these newly formatted dates to pltdates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltdates = []\n",
    "for i in dates:\n",
    "    year = i[0:4]\n",
    "    month = i[5:7]\n",
    "    date = datetime.datetime(int(year),int(month),1)\n",
    "    pltdates.append(matplotlib.dates.date2num(date))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the dates using plt.plot_date\n",
    "We use the linestyle = '-' to show a line graph, rather than simply a scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot_date(pltdates,postsADay, linestyle = '-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Posts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
